apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.service.name }}
  namespace: {{ .Values.service.namespace }}
  labels:
    app: {{ .Values.service.name }}
spec:
  replicas: {{ .Values.replicas }}
  selector:
    matchLabels:
      app: {{ .Values.service.name }}
  template:
    metadata:
      labels:
        app: {{ .Values.service.name }}
    spec:
      nodeSelector:
        node: "{{ .Values.nodeSelector.node }}"
      runtimeClassName: nvidia
      tolerations:
        - key: "node"
          value: "{{ .Values.nodeSelector.node }}"
          effect: "NoSchedule"
      initContainers:
      - name: wait-for-cache
        image: public.ecr.aws/c9r4x6y5/eyelevel/busybox:latest
        imagePullPolicy: "Always"
        command: ['sh', '-c', "until nc -z {{ .Values.dependencies.cache }}; do echo waiting for cache; sleep 2; done"] 
      containers:
      - name: {{ .Values.service.name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: "{{ .Values.image.pull }}"
        env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
        workingDir: /workspace
        # LOAD_MODEL=yes && LOCAL=0 && export PYTHONPATH=/workspace && celery -A summary.celery.appSummary worker -n summary-w1 --loglevel=INFO --concurrency=1 --queues=summary_inference_queue
        command:
          - /bin/bash
          - -c
          - |
            export PYTHONPATH=/workspace && while true; do sleep 30; done
          #- |
          #  export PYTHONPATH=/workspace && supervisord -c /workspace/supervisord.conf
        securityContext:
          runAsUser: {{ .Values.securityContext.runAsUser }}
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - ps aux | grep 'summary.celery.appSummary' || exit 1
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - ps aux | grep 'summary.celery.appSummary' || exit 1
          initialDelaySeconds: 10
          periodSeconds: 30
        resources:
          limits:
            cpu: "{{ .Values.resources.limits.cpu }}"
            memory: "{{ .Values.resources.limits.memory }}"
            nvidia.com/gpu: {{ .Values.resources.limits.gpu }}
          requests:
            cpu: "{{ .Values.resources.requests.cpu }}"
            memory: "{{ .Values.resources.requests.memory }}"
            nvidia.com/gpu: {{ .Values.resources.requests.gpu }}
        volumeMounts:
        - name: config-volume
          mountPath: /workspace/config.py
          subPath: config.py
        - name: supervisord-volume
          mountPath: /workspace/supervisord.conf
          subPath: supervisord.conf
      volumes:
      - name: config-volume
        configMap:
          name: summary-config-py-map
      - name: supervisord-volume
        configMap:
          name: summary-supervisord-24gb-conf-map